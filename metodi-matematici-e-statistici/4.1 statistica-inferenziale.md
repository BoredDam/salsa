# La statistica inferenziale

La statistica inferenziale è un'insieme di metodologie che hanno, come fine ultimo, il trarre conclusioni su una popolazione a partire da un campione più piccolo.

## Campione

Definiamo **campione di rango $n$** l'insieme di $n$ variabili aleatorie $X_i$ provenienti dalla stessa distribuzione. Nota la distribuzione, ma non i suoi parametri, vogliamo trovare un modo per stimarli. Subentrano quindi gli **stimatori**.

> *Esempio: sappiamo che la tendenza dei voti di un corso di studi segue una Gaussiana, ma non ne conosciamo né la media, né la varianza.*

## Stimatori
Una funzione di variabili aleatorie, è detta **statistica**. 

Se il nostro intento è stimare un parametro $\theta$, utilizzerò una statistica a valori nell'immagine di $\theta$.

Detto ciò, definiamo **stimatore puntuale di $\theta$** una statistica $\hat\theta$ a valori nell'immagine di $\theta$. Definiamo **stimatore non distorto** lo stimatore $\hat\theta$ tale che 

$$
E[\hat\theta] = \theta
$$

## Stimatori non distorti noti

### Media - *media campionaria*
Le variabili aleatorie $X_i$ vengono dalla stessa distribuzione, e hanno media $\mu$.

$$
\overline{X}_n = \frac{1}{n}\sum_{i=1}^{N}X_i
$$

Lo abbiamo già dimostrato in [questi appunti](3.%20legge-dei-grandi-numeri.md).

$$
E[\overline{X}_n] = E[\frac{1}{n}\sum_{i=1}^{n}X_i] = \frac{1}{n}\sum_{i=1}^{n}E[X_i] = \frac{n}{n}\mu = \mu
$$

### Varianza con media nota - *varianza campionaria*

Le variabili aleatorie $X_i$ vengono tutte dalla stessa distribuzione, che ha varianza nota $\sigma^2$. La media, nota, è $\mu$.

$$
\overline\sigma^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \mu)^2
$$


$$
E[\overline\sigma^2] = E[\frac{1}{n}\sum_{i=1}^n (X_i - \mu)^2] = 
$$
$$
= \frac{1}{n}\sum_{i=1}^n E[(X_i - \mu)^2] = \frac{1}{n}\sum_{i=1}^n \sigma^2 = \frac{1}{n}n\sigma^2 = \sigma^2
$$

### Varianza con media non-nota - *media campionaria e stima della varianza*

In questo caso, utilizzeremo la media campionaria, e il seguente stimatore della varianza:

$$
\overline S_n^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \overline X_n)^2
$$

Dimostriamolo il fatto che non è distorto.

Semplifichiamo i calcoli dando una forma più carina a $\sum_{i=1}^n (X_i - \overline X_n)^2$.


$$
\sum_{i=1}^n (X_i - \overline X_n)^2 = \sum_{i=1}^n (X_i^2 - 2X_i +\overline X_n^2) = \sum_{i=1}^n X_i^2 - 2 \overline X_n \sum_{i=1}^n X_i + \sum_{i=1}^n\overline X_n^2 =
$$

$$
\sum_{i=1}^n X_i^2 - 2 n \overline X_n^2 + \sum_{i=1}^n\overline X_n^2 = \sum_{i=1}^n X_i^2 - 2 n \overline X_n^2 + n \overline X_n^2 = \sum_{i=1}^n X_i^2 - n \overline X_n^2
$$

E quindi

$$
\overline S_n^2 = \frac{1}{n-1}\sum_{i=1}^n X_i^2 - \frac{n}{n-1}\overline X_n^2
$$

Calcoliamone il valore atteso

$$
E[\overline S_n^2]= E[\frac{1}{n-1}\sum_{i=1}^n X_i^2 - \frac{n}{n-1}\overline X_n^2] = \frac{1}{n-1}\sum_{i=1}^n E[X_i^2] - \frac{n}{n-1} E[\overline X_n^2] = 
$$

$$
= \frac{1}{n-1}\sum_{i=1}^n (\sigma^2 + \mu^2) - \frac{n}{n-1} (\mu^2 +\frac{\sigma^2}{n}) = \frac{n}{n-1} (\sigma^2 + \mu^2) - \frac{n}{n-1} (\mu^2  +\frac{\sigma^2}{n})
$$

$$
= \frac{n}{n-1} (\sigma^2 + \mu^2 - \mu^2  -\frac{\sigma^2}{n}) = \sigma^2
$$