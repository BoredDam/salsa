# Legge dei Grandi Numeri (in forma debole)

*È la legge che si pone come ponte tra il mondo della teoria e quello della pratica.*

Al crescere del numero dei campioni valutati, la differenza tra la  media campionaria e la media teorica tende a 0.

$$
\lim_{n \to \infty} P(|\overline{X}_n - \mu| \leq \eta) = 0 \qquad \forall\eta \geq 0
$$

## Dimostrazione

Tre passi.

1. Disuguaglianza di Markov
2. Disuguaglianza di Chebysev
3. Dimostrazione effettiva

## Disuguaglianza di Markov

Sia $X$ una variabile aleatoria non-negativa: $X \geq 0$. Allora, è vero che

$$
P(X \geq \alpha) \leq \frac{E[X]}{\alpha} \qquad \forall\alpha > 0
$$


### Dimostrazione disuguaglianza di Markov

Definiamo $I$ variabile aleatoria.

$$
I = \begin{cases}
1 \quad \text{se}\quad X \geq \alpha \implies \frac{X}{\alpha} \geq 1\\
0 \quad \text{se}\quad X < \alpha \implies \frac{X}{\alpha} < 1
\end{cases}
$$

Osserviamo che 
$$
0 \leq I \leq \frac{X}{\alpha}
$$

Quindi, per la monotonia delle variabili aleatorie, sappiamo anche che

$$
E[I] \leq E\left[\frac{X}{\alpha}\right] = \frac{E[X]}{\alpha}
$$

Facciamo un'ultima osservazione, calcolando il valore atteso di $I$:

$$
E[I] = 1\cdot P(I = 1) + 0\cdot P(I = 0) = P(I = 1) = P(X \geq\alpha) 
$$

E quindi, come volevasi dimostrare

$$
P(X \geq \alpha) \leq \frac{E[X]}{\alpha} \qquad \forall\alpha > 0
$$

## Disuguaglianza di Chebysev

Sia $X$ una variabile a termini positivi con media e varianza finiti ($E[X], \text{Var}(X) > 0$), allora:

$$
P(|X - E[X]| \geq \eta) \leq \frac{\text{Var}(X)}{\eta^2}
$$

### Dimostrazione disuguaglianza di Chebysev

Definiamo $Y$ variabile aleatoria:

$$
Y = (X - E[X])^2 
$$

Essendo questa un quadrato, è sempre non-negativa, quindi vale la disuguaglianza di Markov. Inoltre, osserviamo che $E[Y] = \text{Var}(X)$.

$$
P((X - E[X])^2  \geq \alpha) \leq \frac{\text{Var}(X)}{\alpha}
$$

Poniamo adesso $\alpha = \eta^2$. 

$$
P((X - E[X])^2  \geq \eta^2) \leq \frac{\text{Var}(X)}{\eta^2}
$$

Finiamo mettendo sotto radice entrambi i membri della disequazione $(X - E[X])^2 \geq \eta^2$.

$$
P(|X - E[X]|  \geq \eta) \leq \frac{\text{Var}(X)}{\eta^2}
$$

Come volevasi dimostrare.

## Dimostrazione della legge dei grandi numeri in forma debole

### Successioni di variabili aleatorie
Definiamo un paio di concetti.

Una **successione di variabili aleatorie** $(X_n)_{n \in \mathbb{N}}$ è una successione di variabili aleatorie indipendenti e appartenenti allo stesso spazio di probabilità.

Una successione di variabili aleatorie **converge in probabilità** se

$$
\lim_{n \to \infty} P(|X_n - X| > \mu) = 0 \qquad \forall\eta > 0
$$

e si scriverà $X_n \xrightarrow{\mathcal{P}}X$.


Analogamente, una successione di variabili aleatorie **converge in legge** se

$$
\lim_{n \to \infty} F_n(t) = F(t)
$$

e si scriverà $X_n \xrightarrow{\mathcal{L}}X$.

### Media campionaria

Definiamo una variabile aleatoria $\overline{X}_n$, nota come **media campionaria**.

$$
\overline{X}_n = \frac{1}{n}\sum_{i=1}^{n}X_i
$$

E supponiamo che le $X_i$ abbiano media $\mu$ e varianza $\sigma^2$.

$$
E[\overline{X}_n] = E[\frac{1}{n}\sum_{i=1}^{n}X_i] = \frac{1}{n}\sum_{i=1}^{n}E[X_i] = \frac{n}{n}\mu = \mu 
$$

$$
\text{Var}(\overline{X}_n) = \text{Var}(\frac{1}{n}\sum_{i=1}^{n}X_i) = \frac{1}{n^2}\text{Var}(\sum_{i=1}^{n}X_i) = \frac{1}{n^2}\sum_{i=1}^{n}\text{Var}(X_i)
$$

$$
= \frac{1}{n^2}\sum_{i=1}^{n}\sigma^2 = \frac{\sigma^2}{n}
$$

### Applichiamo la disuguaglianza di Chebysev

$$
P(|E[\overline{X}_n] - \overline{X}_n|  \geq \eta) \leq \frac{\text{Var}(\overline{X}_n)}{\eta^2} \qquad \forall\eta
$$

Avendo noti i valori di $E[\overline{X}_n]$ e $\text{Var}(\overline{X}_n)$, possiamo sostituire.

$$
P(|\overline{X}_n - \mu|  \geq \eta) \leq \frac{\sigma^2}{n\eta^2} \xrightarrow{n \to \infty} 0 \qquad \forall\eta
$$

Come volevasi dimostrare.