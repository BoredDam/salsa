# 2. Variabili Aleatorie

## Definizione informale

Una **variabile aleatoria**, nota anche come *random variable* o *stochastic variable* è una variabile cui valore dipende dal risultato di un esperimento.

## Definizione formale di variabile aleatoria

Dato uno spazio di probabilità $(\Omega, \mathcal{A}, P)$, definiamo variabile aleatoria un'applicazione del tipo

$$
X : \Omega \to \mathbb{R} \quad : \quad \{\omega : X(\omega) \leq t\} \in \mathcal{A}
$$

## Variabili aleatorie discrete e continue

- Discrete: l'insieme $X(\Omega)$ è finito o enumerabile.

- Continue: l'insieme $X(\Omega)$ è infinito o non enumerabile.

## Legge o Distribuzione di $X$

$$
P(X \in A) \quad \forall \subset \mathbb{R}
$$

> *A probability distribution contains only the possible cases (outcomes) for a variable. It assigns a probability to each possible outcome, and the sum of all probabilities must equal one. Cases with a probability of zero are not included in the distribution because they are impossible outcomes.* 

```
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡀⠀⠀⠀⠀
⠀⠀⠀⠀⢀⡴⣆⠀⠀⠀⠀⠀⣠⡀⠀⠀⠀⠀⠀⠀⣼⣿⡗⠀⠀⠀⠀
⠀⠀⠀⣠⠟⠀⠘⠷⠶⠶⠶⠾⠉⢳⡄⠀⠀⠀⠀⠀⣧⣿⠀⠀⠀⠀⠀
⠀⠀⣰⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⣤⣤⣤⣤⣤⣿⢿⣄⠀⠀⠀⠀
⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣧⠀⠀⠀⠀⠀⠀⠙⣷⡴⠶⣦
⠀⠀⢱⡀⠀⠉⠉⠀⠀⠀⠀⠛⠃⠀⢠⡟⠀⠀⠀⢀⣀⣠⣤⠿⠞⠛⠋
⣠⠾⠋⠙⣶⣤⣤⣤⣤⣤⣀⣠⣤⣾⣿⠴⠶⠚⠋⠉⠁⠀⠀⠀⠀⠀⠀
⠛⠒⠛⠉⠉⠀⠀⠀⣴⠟⢃⡴⠛⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠛⠛⠋⠁⠀⠀
                        help⠀⠀
```

# Variabili aleatorie discrete

Sia $X$ una variabile alaetoria discreta, e consideriamo $A \in \mathbb{R}$. Scriviamolo quindi come unione dei suoi elementi, ottenendo

$$
P(X \in A) = P( X \in \bigcup_{a \in A} \{a\}) = \sum_{a \in A} P(X=a)
$$

## Densità discreta (o *probability mass function*)

È una funzione che associa al valore di una variabile aleatoria la sua probabilità.

$$
p(x) = P(X=x)
$$

Gode di due proprietà (anche se le vedo più come implicazioni dirette del fatto che sia una probabilità):

- $p(x) \geq 0 \quad \forall x \in \mathbb{R}$
- $\sum_{x \in \mathbb{R}} p(x) = 1$

## Funzione di ripartizione (o *funzione cumulativa*)

$$
F_X(t) = P(X \leq t) = \sum_{x \leq t}p(x)
$$

Banalmente, parlando di probabilità, abbiamo:

$$
F_X : \mathbb{R} \to [0,1]
$$

## Speranza matematica (o *valore atteso*)

> *Il valore atteso di una variabile aleatoria $X$ è un numero indicato $\mathbb{E}[X]$ con che formalizza l'idea euristica di valore medio di un fenomeno aleatorio.*

Definisco **speranza matematica** la quantità:

$$
E[X] = \sum_{i=1}^\infty x_i p(x_i)
$$

Gode di alcune proprietà (vere, stavolta :c):

- **Linearità**
    - $E[cX] = cE[X]$
    - $E[X+Y] = E[X] + E[Y]$

- **Monotonia**

    $p(x \leq 1) = 1 \Rightarrow E[X] \leq E[Y]$

- Speranza matematica e valore assoluto

    $|E[X]| \leq E[|X|]$

- Se X e Y sono due variabili aleatorie indipendenti tra loro

    $E[XY] = E[X]E[Y]$

## Momenti di ordine $k$

Il valore atteso della potenza $k$-esima di una variabile aleatoria $X$ è detta **momento di ordine $k$**.

$$
E[X^k] = \sum_{i=1}^\infty x_i^k p(x_i)
$$

## Momento centrato (di ordine $k$)

È possibile ottenere il momento centrato sottraendo la media. Questo aiuta molto a descrivere le caratteristiche di una distribuzione.

$$
E[(X-E[X])^k] = \sum_{i=1}^\infty (x_i-E[X])^k p(x_i)
$$

## Varianza

È il momento centrato di ordine 2. Misura la distanza media dei dati dalla speranza matematica. Gode inoltre delle seguenti proprietà:
 
$$
Var(X) = E[X^2] - E[X]^2
$$

$$
Var(aX) = a^2Var(x)
$$

$$
Var(a+X) = Var(x)
$$

E la indichiamo anche con $\sigma^2$.

## Deviazione standard

$$
\sqrt{\sigma_X^2} = \sigma_X
$$

## Covarianza

$$
Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]
$$

Tiene il conto di come cambia $X$ relativamente a $Y$. Covarianza 0 indica quasi zero correlazione tra $X$ e $Y$.

> *Se $X$ e $Y$ sono direttamente proporzionali, la loro covarianza è positiva. Se sono inversamente proporzionali, la covarianza è negativa*.